{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for '大' not found in /Users/fanyuxin/Desktop/ShanghiTech/2024_autumn/计算机视觉/Project/zcb_input.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "\n",
    "# Simulate retrieving files from a directory\n",
    "# For this example, the images need to be in a specific folder.\n",
    "# Assuming we have individual image files for each character in a directory.\n",
    "# The folder structure and filenames need to be set as per the user's environment.\n",
    "# Replace with the actual directory containing images\n",
    "# \n",
    "#image_folder = \"./123/Chinese_User_3_full\"\n",
    "image_folder = \"/Users/fanyuxin/Desktop/ShanghiTech/2024_autumn/计算机视觉/Project/zcb_input\"\n",
    "\n",
    "# Target phrase to render\n",
    "phrase = \"大\"\n",
    "\n",
    "# Function to find image paths for each character in the phrase\n",
    "\n",
    "\n",
    "def find_images_for_phrase(phrase, folder):\n",
    "    images = []\n",
    "    for char in phrase:\n",
    "        char_filename = f\"{char}.png\"\n",
    "        char_path = os.path.join(folder, char_filename)\n",
    "        if os.path.exists(char_path):\n",
    "            images.append(char_path)\n",
    "        else:\n",
    "            print(f\"Image for '{char}' not found in {folder}.\")\n",
    "    return images\n",
    "\n",
    "\n",
    "# Find images\n",
    "image_paths = find_images_for_phrase(phrase, image_folder)\n",
    "\n",
    "# Combine images into a single row\n",
    "\n",
    "\n",
    "def combine_images_horizontally(image_paths):\n",
    "    images = [Image.open(img_path) for img_path in image_paths]\n",
    "    widths, heights = zip(*(img.size for img in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    combined_image = Image.new(\"RGB\", (total_width, max_height), \"white\")\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        combined_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.size[0]\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "\n",
    "# Generate the combined image\n",
    "if image_paths:\n",
    "    combined_image = combine_images_horizontally(image_paths)\n",
    "    output_path = \"./combined_phrase_image.png\"\n",
    "    combined_image.save(output_path)\n",
    "    output_path\n",
    "else:\n",
    "    \"No images were found for the given phrase.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing individual character images\n",
    "# image_folder = \"./Chinese_User\"\n",
    "\n",
    "# Target phrase to render\n",
    "phrase = \"人才力气大人才力气大人才力气大人才力气大人才力气大\"\n",
    "# phrase = \"全面建设社会主义现代化国家实现新时代新征程各项目标任务关键在党持之以恒推进全面从严治党深入推进新时代党的建设新的伟大工程就要做到坚持和加强党的全面领导与坚持全面从严治党有机统一坚持思想建党与制度治党同向发力坚持人民监督与自我革命相互结合坚持全面推进与突出重点相辅相成坚持着力治标与注重治本同频共振\"\n",
    "\n",
    "# Transformation matrix: (scale, rotation_angle, translate_x, translate_y)\n",
    "# Replace this with the actual transformation matrix\n",
    "# transform_matrix = [\n",
    "#     # scale, rotation_angle, translate_x, translate_y\n",
    "#     [1.0, 0, 0, 15],\n",
    "#     [0.8, 15, 10, 20],\n",
    "#     [1.2, -30, 50, 50],\n",
    "#     [1.0, 10, -60, 100],\n",
    "#     [1.0, 10, -60, 100],\n",
    "# ]\n",
    "\n",
    "# transform_matrix=np.tile(transform_matrix,(20,1)).tolist()\n",
    "transform_matrix = np.zeros((len(phrase), 4))\n",
    "transform_matrix[:,0] = np.random.normal(1,0.2,len(phrase))\n",
    "transform_matrix[:,1] = np.random.normal(0,15,len(phrase))\n",
    "transform_matrix[:,2] = np.random.normal(0,15,len(phrase))\n",
    "transform_matrix[:,3] = np.random.normal(0,50,len(phrase))\n",
    "transform_matrix = transform_matrix.tolist()\n",
    "\n",
    "# Ensure the transformation matrix matches the phrase length\n",
    "assert len(transform_matrix) == len(\n",
    "    phrase), \"Transformation matrix must match the phrase length.\"\n",
    "\n",
    "# Function to find image paths for each character in the phrase\n",
    "\n",
    "def find_images_for_phrase(phrase, folder):\n",
    "    images = []\n",
    "    for char in phrase:\n",
    "        char_filename = f\"{char}.jpg\"\n",
    "        char_path = os.path.join(folder, char_filename)\n",
    "        if os.path.exists(char_path):\n",
    "            images.append(char_path)\n",
    "        else:\n",
    "            print(f\"Image for '{char}' not found in {folder}. Using placeholder.\")\n",
    "            # Create a placeholder blank image if not found\n",
    "            # Adjust size as needed\n",
    "            blank_image = Image.new(\"RGB\", (50, 50), \"white\")\n",
    "            images.append(blank_image)\n",
    "    return images\n",
    "\n",
    "# Combine images with transformations\n",
    "\n",
    "\n",
    "def combine_images_with_transformations(images, transform_matrix):\n",
    "    total_width = 0\n",
    "    max_height = 0\n",
    "\n",
    "    transformed_images = []\n",
    "    x_offset = 0  # Starting x-offset\n",
    "    for i, img in enumerate(images):\n",
    "        if isinstance(img, str):\n",
    "            img = Image.open(img)\n",
    "        scale, rotation, translate_x, translate_y = transform_matrix[i]\n",
    "        translate_x = int(translate_x)\n",
    "        translate_y = int(translate_y)\n",
    "\n",
    "        # Apply scaling\n",
    "        width, height = img.size\n",
    "        new_size = (int(width * scale), int(height * scale))\n",
    "        img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Apply rotation\n",
    "        img = img.rotate(rotation, expand=True,fillcolor=\"white\")\n",
    "\n",
    "        # Update offsets\n",
    "        x_offset += translate_x\n",
    "        y_offset = translate_y\n",
    "\n",
    "        # Keep track of max height for canvas sizing\n",
    "        max_height = max(max_height, img.size[1] + abs(y_offset))\n",
    "\n",
    "        # Append transformed image with its position\n",
    "        transformed_images.append((img, x_offset, y_offset))\n",
    "        x_offset += img.size[0]  # Add the width of the current image\n",
    "\n",
    "    # Create a blank canvas for the combined image\n",
    "    total_width = x_offset\n",
    "    canvas = Image.new(\"RGB\", (total_width, max_height), \"white\")\n",
    "\n",
    "    # Place transformed images onto the canvas\n",
    "    current_x = 0\n",
    "    for img, x_offset, y_offset in transformed_images:\n",
    "        canvas.paste(img, (x_offset, y_offset))\n",
    "        current_x += img.size[0] + translate_x\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "# Load images for the characters\n",
    "image_paths = find_images_for_phrase(phrase, image_folder)\n",
    "\n",
    "# Generate the combined image\n",
    "# if image_paths:\n",
    "#     combined_image = combine_images_with_transformations(\n",
    "#         image_paths, transform_matrix)\n",
    "#     output_path = \"./combined_transformed_phrase_image.png\"\n",
    "#     combined_image.save(output_path)\n",
    "#     print(f\"Output saved to {output_path}\")\n",
    "# else:\n",
    "#     print(\"No images were found for the given phrase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to ./combined_transformed_phrase_with_linebreaks.png\n"
     ]
    }
   ],
   "source": [
    "def combine_images_with_line_breaks(images, transform_matrix, max_line_width):\n",
    "    x_offset = 0  # Starting x-offset\n",
    "    y_offset = 0  # Starting y-offset\n",
    "    line_height = 0  # Height of the current line\n",
    "    max_width = 0\n",
    "    total_height = 0\n",
    "\n",
    "    transformed_images = []\n",
    "    for i, img in enumerate(images):\n",
    "        if isinstance(img, str):\n",
    "            img = Image.open(img)\n",
    "        scale, rotation, translate_x, translate_y = transform_matrix[i]\n",
    "        translate_x = int(translate_x)\n",
    "        translate_y = int(translate_y)\n",
    "\n",
    "        # Apply scaling\n",
    "        width, height = img.size\n",
    "        new_size = (int(width * scale), int(height * scale))\n",
    "        img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Apply rotation\n",
    "        img = img.rotate(rotation, expand=True, fillcolor=\"white\")\n",
    "\n",
    "        # Check if we need to wrap to the next line\n",
    "        if x_offset + img.size[0] > max_line_width:\n",
    "            x_offset = 0\n",
    "            y_offset += line_height  # Move down by the height of the tallest image in the line\n",
    "            line_height = 0  # Reset line height for the new line\n",
    "\n",
    "        # Update line height\n",
    "        line_height = max(line_height, img.size[1])\n",
    "\n",
    "        # Append transformed image with its position\n",
    "        transformed_images.append((img, x_offset, y_offset))\n",
    "\n",
    "        # Update offsets for the next image\n",
    "        x_offset += img.size[0] + translate_x\n",
    "        max_width = max(max_width, x_offset)\n",
    "        total_height = max(total_height, y_offset + line_height)\n",
    "\n",
    "    # Create a blank canvas for the combined image\n",
    "    canvas = Image.new(\"RGB\", (max_line_width, total_height), \"white\")\n",
    "\n",
    "    # Place transformed images onto the canvas\n",
    "    for img, x_pos, y_pos in transformed_images:\n",
    "        canvas.paste(img, (x_pos, y_pos))\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "# Specify the maximum line width for wrapping (e.g., 800 pixels)\n",
    "max_line_width = 3000\n",
    "\n",
    "# Generate the combined image with line breaks\n",
    "if image_paths:\n",
    "    try:\n",
    "        combined_image = combine_images_with_line_breaks(\n",
    "            image_paths, transform_matrix, max_line_width)\n",
    "        output_path = \"./combined_transformed_phrase_with_linebreaks.png\"\n",
    "        combined_image.save(output_path)\n",
    "        print(f\"Output saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during image generation: {e}\")\n",
    "else:\n",
    "    print(\"No images were found for the given phrase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to ./combined_transformed_phrase_with_pixel_blending.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def combine_images_with_pixel_blending(images, transform_matrix, max_line_width, line_spacing=50):\n",
    "    x_offset = 0  # Starting x-offset\n",
    "    y_offset = 0  # Starting y-offset\n",
    "    line_height = 0  # Height of the current line\n",
    "    max_width = 0\n",
    "    total_height = 0\n",
    "\n",
    "    transformed_images = []\n",
    "    for i, img in enumerate(images):\n",
    "        if isinstance(img, str):\n",
    "            img = Image.open(img)\n",
    "        scale, rotation, translate_x, translate_y = transform_matrix[i]\n",
    "        translate_x = int(translate_x)\n",
    "        translate_y = int(translate_y)\n",
    "\n",
    "        # Apply scaling\n",
    "        width, height = img.size\n",
    "        new_size = (int(width * scale), int(height * scale))\n",
    "        img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Apply rotation\n",
    "        img = img.rotate(rotation, expand=True, fillcolor=\"white\")\n",
    "\n",
    "        # Ensure image has an alpha channel for blending\n",
    "        img = img.convert(\"RGBA\")\n",
    "\n",
    "        # Check if we need to wrap to the next line\n",
    "        if x_offset + img.size[0] > max_line_width:\n",
    "            x_offset = 0\n",
    "            y_offset += line_height+line_spacing  # Move down by the height of the tallest image in the line\n",
    "            line_height = 0  # Reset line height for the new line\n",
    "\n",
    "        # Update line height\n",
    "        line_height = max(line_height, img.size[1])\n",
    "\n",
    "        # Append transformed image with its position\n",
    "        transformed_images.append((img, x_offset, y_offset))\n",
    "\n",
    "        # Update offsets for the next image\n",
    "        x_offset += img.size[0] + translate_x\n",
    "        max_width = max(max_width, x_offset)\n",
    "        total_height = max(total_height, y_offset + line_height)\n",
    "\n",
    "    # Create a blank RGBA canvas for the combined image\n",
    "    canvas = Image.new(\"RGBA\", (max_line_width, total_height),\n",
    "                       (255, 255, 255, 255))  # White background\n",
    "\n",
    "    # Convert canvas to numpy array for faster processing\n",
    "    canvas_array = np.array(canvas)\n",
    "\n",
    "    # Place transformed images onto the canvas with pixel-level blending using numpy\n",
    "    for img, x_pos, y_pos in transformed_images:\n",
    "        img_array = np.array(img)  # Convert image to numpy array\n",
    "        h, w, _ = img_array.shape\n",
    "\n",
    "        # Extract the region from the canvas where the current image will be placed\n",
    "        canvas_region = canvas_array[y_pos:y_pos + h, x_pos:x_pos + w]\n",
    "\n",
    "        # Calculate brightness for blending\n",
    "        canvas_brightness = 0.299 * canvas_region[:, :, 0] + \\\n",
    "            0.587 * canvas_region[:, :, 1] + \\\n",
    "            0.114 * canvas_region[:, :, 2]\n",
    "        img_brightness = 0.299 * img_array[:, :, 0] + \\\n",
    "            0.587 * img_array[:, :, 1] + \\\n",
    "            0.114 * img_array[:, :, 2]\n",
    "\n",
    "        # Create a mask where the image pixel is darker than the canvas pixel\n",
    "        mask = img_brightness < canvas_brightness\n",
    "\n",
    "        # Blend the image into the canvas\n",
    "        canvas_region[mask] = img_array[mask]\n",
    "\n",
    "        # Update the canvas region\n",
    "        canvas_array[y_pos:y_pos + h, x_pos:x_pos + w] = canvas_region\n",
    "\n",
    "    # Convert numpy array back to PIL Image\n",
    "    final_image = Image.fromarray(canvas_array, mode=\"RGBA\")\n",
    "    return final_image\n",
    "\n",
    "\n",
    "# Specify the maximum line width for wrapping (e.g., 800 pixels)\n",
    "max_line_width = 6000\n",
    "linespacing = 50\n",
    "\n",
    "# Generate the combined image with pixel blending\n",
    "if image_paths:\n",
    "    try:\n",
    "        combined_image = combine_images_with_pixel_blending(\n",
    "            image_paths, transform_matrix, max_line_width,line_spacing=linespacing)\n",
    "        output_path = \"./combined_transformed_phrase_with_pixel_blending.png\"\n",
    "        combined_image.save(output_path)\n",
    "        print(f\"Output saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during image generation: {e}\")\n",
    "else:\n",
    "    print(\"No images were found for the given phrase.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs172a2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
